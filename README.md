# Voice Recognition System

*Note: This README was generated by AI on August 13, 2025*

## Overview

This project provides a multi-provider voice recognition system capable of detecting languages from audio input using various AI services. It features Voice Activity Detection (VAD) and audio chunking for efficient processing across all supported providers.

## Features

- **Multi-Provider Support**: Compatible with ElevenLabs, OpenAI, Google Gemini, and Sarvam AI
- **Voice Activity Detection (VAD)**: Filters out silence and non-speech segments
- **Audio Chunking**: Processes long audio files in manageable chunks
- **Language Detection**: Identifies spoken language in audio files
- **Provider Voting**: Aggregates language detection results for higher accuracy

## Installation

1. Clone the repository

```bash
git clone https://github.com/your-username/voice_recognition.git
cd voice_recognition
```

2. Install dependencies

```bash
pip install -r requirements.txt
```

## Configuration

Set up your API keys for the providers you wish to use. Create a `.env` file in the root directory:

```
# API Keys
ELEVENLABS_API_KEY=your_elevenlabs_api_key
OPENAI_API_KEY=your_openai_api_key
GEMINI_API_KEY=your_gemini_api_key
SARVAM_API_KEY=your_sarvam_api_key

# Optional Configuration
CHUNK_LENGTH_MS=20000
VAD_AGGRESSIVENESS=2
```

## Usage

### Basic Usage

```python
# Choose your preferred connector
from connectors import ElevenLabs_Connector

# Initialize the connector
connector = ElevenLabs_Connector()

# Detect language from audio file
result = connector.detect_language("path/to/audio.mp3")
print(f"Detected language: {result}")
```

### API Endpoints

The system provides a FastAPI web server with the following endpoints:

#### POST `/detect/language`

Detects the language spoken in an audio file.

**Request Body:**
```json
{
  "audio_path": "path/to/audio.mp3",
  "ground_truth_language": "en"  // Optional ground truth for evaluation
}
```

**Response:**
```json
{
  "status": "success",
  "detected_language": "en",
  "processing_time_seconds": 1.23,
  "provider_results": [
    {
      "provider": "ElevenLabs",
      "language": "en",
      "processing_time": 0.86,
      "cost": 0.0002
    },
    // Results from other providers
  ]
}
```

#### GET `/providers`

Lists all available language detection providers.

**Response:**
```json
{
  "providers": [
    {
      "name": "ElevenLabs",
      "status": "available"
    },
    // Other providers
  ]
}
```

#### GET `/health`

Health check endpoint.

**Response:**
```json
{
  "status": "healthy",
  "providers_available": 4
}
```

### Running the API Server

```bash
# Start the API server
python main.py
```

The server runs on `http://localhost:8000` by default.

## Supported Providers

### ElevenLabs

Provides high-quality language detection with a language voting system across chunks.

```python
from connectors import ElevenLabs_Connector

connector = ElevenLabs_Connector()
result = connector.detect_language("path/to/audio.mp3")
```

### OpenAI

Leverages OpenAI's language detection capabilities with VAD-enhanced chunking.

```python
from connectors import OpenAI_Connector

connector = OpenAI_Connector()
result = connector.detect_language("path/to/audio.mp3")
```

### Google Gemini

Implements VAD with chunking and token accumulation across chunks.

```python
from connectors import Gemini_Connector

connector = Gemini_Connector()
result = connector.detect_language("path/to/audio.mp3")
```

### Sarvam AI

Utilizes efficient audio chunking with Sarvam's language detection API.

```python
from connectors import Sarvam_AI_Connector

connector = Sarvam_AI_Connector()
result = connector.detect_language("path/to/audio.mp3")
```

## Audio Processing Utilities

The system includes utilities for audio validation and processing:

```python
from utils.audio_validator import (
    validate_audio_file,
    split_audio_into_chunks,
    detect_speech_in_audio
)

# Validate audio file
valid = validate_audio_file("path/to/audio.mp3")

# Split audio into chunks
chunks = split_audio_into_chunks("path/to/audio.mp3", chunk_length_ms=20000)

# Apply VAD to detect speech segments
speech_chunks = detect_speech_in_audio(chunks, vad_aggressiveness=2)
```

## Architecture

The system follows a modular architecture:

- **Connectors**: Provider-specific implementations for language detection
- **Utils**: Shared utilities for audio processing and validation
- **Core**: Main interface for the voice recognition system

All connectors use standardized parameters:
- `chunk_length_ms = 20000` (20 second chunks)
- `vad_aggressiveness = 2` (medium filtering)

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.
